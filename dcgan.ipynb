{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!export CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as weight_init\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class netG(nn.Module):\n",
    "    def __init__(self, nz, ngf, nc):\n",
    "        super(netG, self).__init__()\n",
    "               \n",
    "        self.convT_1 = nn.ConvTranspose2d(nz, ngf*8, 4, 1, 0, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(ngf*8)\n",
    "        \n",
    "        self.convT_2 = nn.ConvTranspose2d(ngf*8, ngf*4, 4, 2, 1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(ngf*4)\n",
    "        \n",
    "        self.convT_3 = nn.ConvTranspose2d(ngf*4, ngf*2, 4, 2, 1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(ngf*2)\n",
    "        \n",
    "        self.convT_4 = nn.ConvTranspose2d(ngf*2, ngf, 4, 2, 1, bias=False)\n",
    "        self.bn4 = nn.BatchNorm2d(ngf)\n",
    "        \n",
    "        self.convT_5 = nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False)\n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.ConvTranspose2d):\n",
    "                weight_init.kaiming_normal(m.weight)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.normal_(1.0, 0.01)\n",
    "                m.bias.data.fill_(0)\n",
    "\n",
    "    def forward(self, input):\n",
    "        out = F.relu(self.bn1(self.convT_1(input)))\n",
    "        out = F.relu(self.bn2(self.convT_2(out)))\n",
    "        out = F.relu(self.bn3(self.convT_3(out)))\n",
    "        out = F.relu(self.bn4(self.convT_4(out)))\n",
    "        out = F.tanh(self.convT_5(out))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class netD(nn.Module):\n",
    "    def __init__(self, nc, ndf, nz):\n",
    "        super(netD, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(nc, ndf, 4, 2, 1, bias=False)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(ndf, ndf*2, 4, 2, 1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(ndf*2)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(ndf*2, ndf*4, 4, 2, 1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(ndf*4)\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(ndf*4, ndf*8, 4, 2, 1, bias=False)\n",
    "        self.bn4 = nn.BatchNorm2d(ndf*8)\n",
    "        \n",
    "        self.conv5 = nn.Conv2d(ndf*8, 1, 4, 1, 0, bias=False)\n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.ConvTranspose2d):\n",
    "                weight_init.kaiming_normal(m.weight)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.normal_(1.0, 0.01)\n",
    "                m.bias.data.fill_(0)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        out = F.leaky_relu(self.conv1(input), 0.2, inplace=True)\n",
    "        \n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out = F.leaky_relu(out, 0.2, inplace=True)\n",
    "        \n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out = F.leaky_relu(out, 0.2, inplace=True)\n",
    "\n",
    "        out = self.bn4(self.conv4(out))\n",
    "        out = F.leaky_relu(out, 0.2, inplace=True)\n",
    "        \n",
    "        out = self.conv5(out)\n",
    "        \n",
    "        out = F.sigmoid(out)\n",
    "        out =  out.view(-1, 1).squeeze(1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#opts\n",
    "LR = 0.0002\n",
    "beta1 = 0.5\n",
    "\n",
    "NITER = 100\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "nz = int(100)\n",
    "ngf = int(64)\n",
    "ndf = int(64)\n",
    "nc = 3\n",
    "\n",
    "outf = './'\n",
    "DATA_ROOT = './data'\n",
    "try:\n",
    "    os.makedirs(outf)\n",
    "except: pass\n",
    "\n",
    "cudnn.benchmark = True\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = dset.MNIST(root=DATA_ROOT, download=True,\n",
    "                           transform=transforms.Compose([\n",
    "                               transforms.Scale(64),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "]))\n",
    "\n",
    "# dataset = dset.LSUN(db_path=DATA_ROOT, classes=['bedroom_train'],\n",
    "#                         transform=transforms.Compose([\n",
    "#                             transforms.Scale(64),\n",
    "#                             transforms.CenterCrop(64),\n",
    "#                             transforms.ToTensor(),\n",
    "#                             transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "# ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE,\n",
    "                                         shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G = netG(nz, ngf, nc).cuda()\n",
    "D = netD(nc, ndf, nz).cuda()\n",
    "criterion = nn.BCELoss().cuda()\n",
    "\n",
    "noise = torch.FloatTensor(BATCH_SIZE, nz, 1, 1).cuda()\n",
    "fixed_noise = Variable(torch.FloatTensor(BATCH_SIZE, nz, 1, 1).normal_(0, 1)).cuda()\n",
    "\n",
    "real_label = 1\n",
    "fake_label = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer_G = optim.Adam(G.parameters(), lr=LR, betas=(beta1 ,0.999))\n",
    "optimizer_D = optim.Adam(D.parameters(), lr=LR, betas=(beta1 ,0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(NITER):\n",
    "    for i, data in enumerate(dataloader):\n",
    "        # Discriminator\n",
    "        D.zero_grad()\n",
    "        \n",
    "        # Discriminator Feed real data\n",
    "        real, _ = data\n",
    "        batch_size = real.size(0)\n",
    "        \n",
    "        real = Variable(real).cuda()\n",
    "        label = Variable(torch.Tensor(batch_size).fill_(real_label)).cuda()\n",
    "        \n",
    "        output = D(real)\n",
    "        errD_real = criterion(output, label)\n",
    "        errD_real.backward()\n",
    "        \n",
    "        D_x = output.data.mean()\n",
    "        \n",
    "        # Feed fake data\n",
    "        noise.resize_(batch_size, nz, 1, 1).normal_(0,1)\n",
    "        noisev = Variable(noise)\n",
    "        label = Variable(torch.Tensor(batch_size).fill_(fake_label)).cuda()\n",
    "        \n",
    "        fake = G(noisev)\n",
    "        output = D(fake.detach())\n",
    "        errD_fake = criterion(output, label)\n",
    "        errD_fake.backward()\n",
    "        \n",
    "        D_G_z1 = output.data.mean()\n",
    "        \n",
    "        errD = errD_real + errD_fake\n",
    "        optimizer_D.step()\n",
    "        \n",
    "        # Generator\n",
    "        G.zero_grad()\n",
    "        label = Variable(torch.Tensor(batch_size).fill_(real_label)).cuda()\n",
    "        output = D(fake)\n",
    "        errG = criterion(output, label)\n",
    "        errG.backward()\n",
    "        optimizer_G.step()\n",
    "        D_G_z2 = output.data.mean()\n",
    "        \n",
    "# if i%100 == 0:\n",
    "    print('[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f / %.4f'\n",
    "          % (epoch, NITER, i, len(dataloader),\n",
    "             errD.data[0], errG.data[0], D_x, D_G_z1, D_G_z2))\n",
    "\n",
    "    vutils.save_image(real.data.cpu(), '%s/real_samples.png' % outf,\n",
    "                                    normalize=True)\n",
    "    fake = G(fixed_noise)\n",
    "    vutils.save_image(fake.data, '%s/fake_samples_epoch_%03d.png' % (outf, i),\n",
    "                                    normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dummy = Variable(torch.Tensor(1,nz,1,1).normal_(0,1)).cuda()\n",
    "out = G(dummy) \n",
    "# out = D(out)\n",
    "# print out\n",
    "out = out.squeeze()\n",
    "out = out.data.cpu().numpy()\n",
    "\n",
    "plt.imshow(out, cmap='Greys')\n",
    "# plt.imshow(np.transpose(out, [1,2,0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
